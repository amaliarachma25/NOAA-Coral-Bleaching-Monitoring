{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "biGFhbeeeJmV",
        "7xoOG4ijeO23",
        "EYDQ3NeqZTAR",
        "32rVMziAeVhh"
      ],
      "mount_file_id": "1-hyRG2fCCMeXlVnFsfdHaW3Tz7m4RzvP",
      "authorship_tag": "ABX9TyOjgj8zWI1BSF31ZuL1aHWz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amaliarachma25/NOAA-Coral-Bleaching-Monitoring/blob/main/NOAA_CRW_Server_Otomasi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåä Automated Pipeline: NOAA Coral Reef Watch Data Processing\n",
        "\n",
        "Project: Monitoring Kesehatan Karang (SST, DHW, SSTA)\n",
        "\n",
        "Notebook ini berfungsi untuk mengunduh data satelit NOAA secara otomatis, memotong area spesifik (Selat Lombok), dan mengekstrak data site berdasarkan batas kawasan konservasi (Shapefile).\n",
        "\n",
        "\n",
        "üìã Alur Kerja (Workflow):\n",
        "\n",
        "1.   Setup: Menyiapkan folder otomatis di Google Drive.\n",
        "2.   Download: Mengambil data harian global dari Server NOAA.\n",
        "3.   Clip Regional: Memotong data global menjadi area kecil (Lombok).\n",
        "4.   Masking Site: Memotong spesifik sesuai bentuk kawasan (Gili Matra, Gita Nada, Nusa Penida) dan convert ke format .xyz.\n",
        "\n",
        "\n",
        "\n",
        "# > ‚ö†Ô∏è WAJIB DILAKUKAN SEBELUM MULAI:\n",
        "\n",
        "Pastikan sudah mengupload folder Shapefile (.shp, .shx, .dbf, dll) ke dalam Google Drive.\n",
        "\n",
        "Lokasi: /MAGANG/CORAL/SHP_SITE/\n",
        "\n",
        "File yang dibutuhkan:\n",
        "\n",
        "*   gili_matra_buffer_5km.shp\n",
        "*   gita_nada_buffer_5km.shp\n",
        "* nusa_penida_buffer_5km.shp\n",
        "\n",
        "# üìÇ Struktur Folder Proyek (Mind Map) (contoh)\n",
        "\n",
        "Pastikan struktur folder di Google Drive (`My Drive/MAGANG/CORAL/...`) sesuai dengan peta di bawah ini agar script berjalan lancar.\n",
        "\n",
        "```text\n",
        "My Drive/\n",
        "‚îî‚îÄ‚îÄ MAGANG/\n",
        "    ‚îî‚îÄ‚îÄ CORAL/  (Folder Utama Proyek)\n",
        "        ‚îÇ\n",
        "        ‚îú‚îÄ‚îÄ [ALUR 1: PENGOLAHAN DATA HARIAN]\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ 01_Global/                     # [Input]  Tempat hasil download NOAA Daily (.nc)\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ 02_Clip_Lombok/                # [Proses] File .nc harian dipotong khusus area Lombok\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ SHP_SITE/                      # [Manual] WAJIB Upload Shapefile (.shp) di sini\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ 03_masking_site/               # [Output] Hasil ekstraksi koordinat (.xyz) per site\n",
        "        ‚îÇ\n",
        "        ‚îú‚îÄ‚îÄ [ALUR 2: PENGOLAHAN CLIMATOLOGY]\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ 01_climatology/\n",
        "        ‚îÇ       ‚îú‚îÄ‚îÄ SHP_SITE/                  # [Manual] Copy Shapefile yang sama ke folder ini\n",
        "        ‚îÇ       ‚îú‚îÄ‚îÄ 00_raw_climatology/        # [Input]  Tempat hasil download Climatology (.nc)\n",
        "        ‚îÇ       ‚îú‚îÄ‚îÄ 03_masking_site_clim/      # [Output] Hasil ekstraksi Climatology per site\n",
        "        ‚îÇ       ‚îî‚îÄ‚îÄ average_climatology.txt    # [Result] File txt berisi nilai MMM & Mean Bulanan\n",
        "        ‚îÇ\n",
        "        ‚îî‚îÄ‚îÄ [ALUR 3: ANALISIS AKHIR]\n",
        "            ‚îî‚îÄ‚îÄ NOAA_Final_Reports # [Final]  Laporan Akhir (BAA, DHW, Percentile)\n",
        "                                               # (Menggabungkan data dari 03_masking_site & average_climatology.txt)\n"
      ],
      "metadata": {
        "id": "bJxixZ8EncYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1 Persiapan Environment\n",
        "\n",
        "Tahap ini akan menginstal alat bantu (library) yang diperlukan untuk mengolah data satelit (xarray, netCDF4) dan menghubungkan Google Colab dengan Google Drive.\n",
        "\n",
        "Apa yang dilakukan script ini?\n",
        "\n",
        "Menginstall library Python.\n",
        "\n",
        "Membuat struktur folder otomatis di Drive :\n",
        "\n",
        "*   01_Global (Untuk data mentah)\n",
        "*   02_Clip_Lombok (Untuk hasil potongan kasar)"
      ],
      "metadata": {
        "id": "biGFhbeeeJmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Drive\n",
        "# Ini akan memunculkan popup meminta izin akses ke Akun Google kamu.\n",
        "# Klik \"Connect to Google Drive\" lalu pilih akunmu dan klik \"Allow/Izinkan\".\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Cek apakah berhasil\n",
        "import os\n",
        "if os.path.exists('/content/drive'):\n",
        "    print(\"‚úÖ Google Drive berhasil terhubung!\")\n",
        "else:\n",
        "    print(\"‚ùå Gagal terhubung.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwUglt3ac93H",
        "outputId": "bc90a468-7623-4fa9-a58e-c658a1d030dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive berhasil terhubung!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install Library yang dibutuhkan (xarray & netCDF4 biasanya perlu install dulu di Colab)\n",
        "!pip install xarray netCDF4 requests\n",
        "\n",
        "# 2. Buat Folder Penyimpanan Sementara di Colab\n",
        "import os\n",
        "\n",
        "# Define the base directory on Google Drive\n",
        "base_drive_dir = \"/content/drive/MyDrive/MAGANG/CORAL\" #diganti sesuai drive sendiri\n",
        "\n",
        "# Ensure the base directory exists\n",
        "if not os.path.exists(base_drive_dir):\n",
        "    try:\n",
        "        os.makedirs(base_drive_dir, exist_ok=True)\n",
        "        print(f\"Created base directory: {base_drive_dir}\")\n",
        "    except OSError as e:\n",
        "        print(f\"‚ùå Error creating base directory {base_drive_dir}: {e}\")\n",
        "\n",
        "# Folder untuk menyimpan file mentah (Raw)\n",
        "raw_dir = os.path.join(base_drive_dir, \"01_Global\") #Buat folder di drive untuk menyimpan hasil global\n",
        "if not os.path.exists(raw_dir):\n",
        "    os.makedirs(raw_dir, exist_ok=True)\n",
        "\n",
        "# Folder untuk menyimpan hasil potongan (Clip)\n",
        "clip_dir = os.path.join(base_drive_dir, \"02_Clip_Lombok\") #Buat folder di drive untuk menyimpan hasil clip\n",
        "if not os.path.exists(clip_dir):\n",
        "    os.makedirs(clip_dir, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Folder siap digunakan!\")\n",
        "print(f\"üìÇ Lokasi Download: {raw_dir}\")\n",
        "print(f\"üìÇ Lokasi Output: {clip_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y-55neueHRz",
        "outputId": "025c8f78-2127-41d7-bdf9-2e355ccf8ceb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (2025.12.0)\n",
            "Collecting netCDF4\n",
            "  Downloading netcdf4-1.7.4-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from xarray) (2.0.2)\n",
            "Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.12/dist-packages (from xarray) (25.0)\n",
            "Requirement already satisfied: pandas>=2.2 in /usr/local/lib/python3.12/dist-packages (from xarray) (2.2.2)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netCDF4) (2026.1.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2->xarray) (1.17.0)\n",
            "Downloading netcdf4-1.7.4-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.6.5 netCDF4-1.7.4\n",
            "‚úÖ Folder siap digunakan!\n",
            "üìÇ Lokasi Download: /content/drive/MyDrive/MAGANG/CORAL/01_Global\n",
            "üìÇ Lokasi Output: /content/drive/MyDrive/MAGANG/CORAL/02_Clip_Lombok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2 Download (Direct Server)\n",
        "\n",
        "Script ini bertugas mengambil data mentah langsung dari server NOAA Coral Reef Watch. Data yang diambil mencakup:\n",
        "\n",
        "SST: Suhu Permukaan Laut.\n",
        "\n",
        "SSTA: Anomali Suhu (Penyimpangan dari rata-rata).\n",
        "\n",
        "HS: HotSpot (Stress panas harian).\n",
        "\n",
        "DHW: Degree Heating Weeks (Akumulasi stress panas/risiko bleaching).\n",
        "\n",
        "Catatan:\n",
        "\n",
        "*   Atur tanggal pada variabel start_date dan end_date sesuai kebutuhan.\n",
        "*   Data akan tersimpan otomatis di folder 01_Global."
      ],
      "metadata": {
        "id": "7xoOG4ijeO23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "# --- KONFIGURASI ---\n",
        "# Kita gunakan folder yang sudah dibuat di Langkah 0\n",
        "save_dir = \"/content/drive/MyDrive/MAGANG/CORAL/01_Global\"\n",
        "\n",
        "# RENTANG TANGGAL\n",
        "start_date = datetime(2025, 12, 31)\n",
        "end_date   = datetime(2025, 12, 31)\n",
        "\n",
        "# URL & CONFIG\n",
        "base_url = \"https://www.star.nesdis.noaa.gov/pub/socd/mecb/crw/data/5km/v3.1_op/nc/v1.0/daily\"\n",
        "\n",
        "var_config = {\n",
        "    \"sst\":  [\"sst\",  \"coraltemp\",  \"NOAA_SST\"],\n",
        "    \"ssta\": [\"ssta\", \"ct5km_ssta\", \"NOAA_SSTA\"],\n",
        "    \"hs\":   [\"hs\",   \"ct5km_hs\",   \"NOAA_HS\"],\n",
        "    \"dhw\":  [\"dhw\",  \"ct5km_dhw\",  \"NOAA_DHW\"]\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "def download_step():\n",
        "    print(f\"--- MULAI DOWNLOAD DATA ---\")\n",
        "    print(f\"Target: {start_date.strftime('%Y-%m-%d')} s/d {end_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    current_date = start_date\n",
        "    while current_date <= end_date:\n",
        "        date_str_url = current_date.strftime(\"%Y%m%d\")\n",
        "        year = current_date.strftime(\"%Y\")\n",
        "        date_disp = current_date.strftime('%Y-%m-%d')\n",
        "\n",
        "        print(f\"[{date_disp}] Memproses...\", end=\" \")\n",
        "\n",
        "        for var_key, config in var_config.items():\n",
        "            folder_server = config[0]\n",
        "            prefix_server = config[1]\n",
        "            prefix_local  = config[2]\n",
        "\n",
        "            local_filename = f\"{prefix_local}_{date_str_url}.nc\"\n",
        "            local_path = os.path.join(save_dir, local_filename)\n",
        "\n",
        "            # Cek jika sudah ada\n",
        "            if os.path.exists(local_path) and os.path.getsize(local_path) > 1000:\n",
        "                continue\n",
        "\n",
        "            # Download\n",
        "            filename_server = f\"{prefix_server}_v3.1_{date_str_url}.nc\"\n",
        "            url = f\"{base_url}/{folder_server}/{year}/{filename_server}\"\n",
        "\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers, stream=True, timeout=60)\n",
        "                if response.status_code == 200:\n",
        "                    with open(local_path, 'wb') as f:\n",
        "                        for chunk in response.iter_content(chunk_size=1024*1024):\n",
        "                            f.write(chunk)\n",
        "                else:\n",
        "                    print(f\"[x] Gagal {var_key.upper()}: {response.status_code}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[!] Error {var_key.upper()}: {e}\")\n",
        "\n",
        "            time.sleep(0.2) # Jeda sopan\n",
        "\n",
        "        print(\"Selesai.\")\n",
        "        current_date += timedelta(days=1)\n",
        "\n",
        "    print(\"\\n‚úÖ Download Selesai. Cek folder di menu file sebelah kiri.\")\n",
        "\n",
        "# Jalankan Fungsi\n",
        "download_step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmoDqJkeeSRw",
        "outputId": "dead8e8e-a968-43c2-c33d-de6bee576846"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MULAI DOWNLOAD DATA ---\n",
            "Target: 2025-12-31 s/d 2025-12-31\n",
            "[2025-12-31] Memproses... Selesai.\n",
            "\n",
            "‚úÖ Download Selesai. Cek folder di menu file sebelah kiri.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3 Clipping (Selat Lombok)\n",
        "Mengolah data global (seluruh dunia) sangat berat dan lambat. Tahap ini akan memotong data global tersebut hanya pada kotak koordinat Selat Lombok dan sekitarnya. Memperkecil ukuran file secara drastis, mempercepat proses masking di tahap selanjutnya. Hasil potongan akan disimpan di folder 02_Clip_lombok."
      ],
      "metadata": {
        "id": "EYDQ3NeqZTAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup & Install Library"
      ],
      "metadata": {
        "id": "oXvgnPoHZxxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xarray netCDF4\n",
        "\n",
        "import xarray as xr\n",
        "import os\n",
        "import glob\n",
        "import warnings\n",
        "import shutil\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Hubungkan Google Drive (Jika belum)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- 2. KONFIGURASI FOLDER INPUT (LANGSUNG DARI DRIVE) ---\n",
        "# Sesuaikan path ini dengan lokasi folder kamu di Google Drive.\n",
        "# Biasanya formatnya: \"/content/drive/MyDrive/NAMA_FOLDER_KAMU/...\"\n",
        "# Contoh: Jika di laptop D:\\magang\\CORAL\\output\\01_hasil_noaa_global\n",
        "# Maka di Drive biasanya:\n",
        "\n",
        "input_dir = \"/content/drive/MyDrive/MAGANG/CORAL/01_Global\"\n",
        "# ^^^ GANTI PATH DI ATAS JIKA NAMA FOLDER DI DRIVE KAMU BERBEDA ^^^\n",
        "\n",
        "# Folder Output (Simpan hasil clip ke Drive juga biar aman)\n",
        "output_dir = \"/content/drive/MyDrive/MAGANG/CORAL/02_Clip_lombok\"\n",
        "\n",
        "# Buat folder output jika belum ada\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# --- 3. CEK APAKAH FILE TERBACA? ---\n",
        "# Kita cek apakah script bisa melihat file .nc di folder itu\n",
        "nc_files = glob.glob(os.path.join(input_dir, \"*.nc\"))\n",
        "\n",
        "print(f\"üìÇ Folder Input: {input_dir}\")\n",
        "print(f\"üìÇ Folder Output: {output_dir}\")\n",
        "print(f\"üîç Ditemukan {len(nc_files)} file .nc\")\n",
        "\n",
        "if len(nc_files) == 0:\n",
        "    print(\"‚ùå PERINGATAN: Tidak ada file .nc ditemukan! Cek lagi path 'input_dir' di atas.\")\n",
        "else:\n",
        "    print(\"‚úÖ File siap diproses! Lanjut ke script clipping di bawah.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQPiswlmijHd",
        "outputId": "774207e9-4bee-4699-9526-321cce4f9431"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (2025.12.0)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.12/dist-packages (1.7.4)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from xarray) (2.0.2)\n",
            "Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.12/dist-packages (from xarray) (25.0)\n",
            "Requirement already satisfied: pandas>=2.2 in /usr/local/lib/python3.12/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.12/dist-packages (from netCDF4) (1.6.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netCDF4) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2->xarray) (1.17.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üìÇ Folder Input: /content/drive/MyDrive/MAGANG/CORAL/01_Global\n",
            "üìÇ Folder Output: /content/drive/MyDrive/MAGANG/CORAL/02_Clip_lombok\n",
            "üîç Ditemukan 5 file .nc\n",
            "‚úÖ File siap diproses! Lanjut ke script clipping di bawah.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script Clipping (Lombok Strait)"
      ],
      "metadata": {
        "id": "2-wgfW6qZqmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import warnings\n",
        "\n",
        "# Abaikan warning\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- KOORDINAT SELAT LOMBOK ---\n",
        "# [115.2, 116.2, -9, -8]\n",
        "lat_min, lat_max = -9, -8\n",
        "lon_min, lon_max = 115.2, 116.2\n",
        "\n",
        "def process_direct_from_drive():\n",
        "    print(\"--- BATCH CLIPPING LOMBOK (DIRECT DRIVE) ---\")\n",
        "\n",
        "    # Ambil list file yang sudah dicek tadi\n",
        "    all_files = glob.glob(os.path.join(input_dir, \"*.nc\"))\n",
        "    total_files = len(all_files)\n",
        "\n",
        "    if total_files == 0:\n",
        "        return\n",
        "\n",
        "    success_count = 0\n",
        "    fail_count = 0\n",
        "\n",
        "    for i, file_path in enumerate(all_files, 1):\n",
        "        filename = os.path.basename(file_path)\n",
        "\n",
        "        # Skip jika file hasil clip (menghindari loop)\n",
        "        if filename.startswith(\"Clip_\"):\n",
        "            continue\n",
        "\n",
        "        print(f\"[{i}/{total_files}] Memproses: {filename} ... \", end='', flush=True)\n",
        "\n",
        "        try:\n",
        "            ds = xr.open_dataset(file_path)\n",
        "\n",
        "            # --- DETEKSI NAMA VARIABEL ---\n",
        "            if 'lat' in ds.coords:\n",
        "                lat_name, lon_name = 'lat', 'lon'\n",
        "            elif 'latitude' in ds.coords:\n",
        "                lat_name, lon_name = 'latitude', 'longitude'\n",
        "            else:\n",
        "                print(\" -> ERROR (Koordinat?)\")\n",
        "                continue\n",
        "\n",
        "            # --- SORTING & SLICING ---\n",
        "            ds = ds.sortby([lat_name, lon_name])\n",
        "\n",
        "            # Lakukan Clipping Area Lombok\n",
        "            ds_clipped = ds.sel({\n",
        "                lat_name: slice(lat_min, lat_max),\n",
        "                lon_name: slice(lon_min, lon_max)\n",
        "            })\n",
        "\n",
        "            # Cek hasil\n",
        "            if ds_clipped.dims[lat_name] == 0 or ds_clipped.dims[lon_name] == 0:\n",
        "                print(\" -> GAGAL (Kosong)\")\n",
        "                fail_count += 1\n",
        "            else:\n",
        "                # Simpan LANGSUNG ke Google Drive\n",
        "                output_filename = f\"Clip_Lombok_{filename}\"\n",
        "                output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "                ds_clipped.to_netcdf(output_path)\n",
        "                print(\" -> SUKSES!\")\n",
        "                success_count += 1\n",
        "\n",
        "            ds_clipped.close()\n",
        "            ds.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" -> ERROR: {e}\")\n",
        "            fail_count += 1\n",
        "\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(f\"SELESAI. Cek folder '{output_dir}' di Google Drive kamu.\")\n",
        "\n",
        "# Jalankan Fungsi\n",
        "process_direct_from_drive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdTixPUmZhJD",
        "outputId": "75584527-792c-490b-865f-92319e05c56c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BATCH CLIPPING LOMBOK (DIRECT DRIVE) ---\n",
            "[1/5] Memproses: NOAA_SST_20251202.nc ...  -> SUKSES!\n",
            "[2/5] Memproses: NOAA_SST_20251231.nc ...  -> SUKSES!\n",
            "[3/5] Memproses: NOAA_SSTA_20251231.nc ...  -> SUKSES!\n",
            "[4/5] Memproses: NOAA_HS_20251231.nc ...  -> SUKSES!\n",
            "[5/5] Memproses: NOAA_DHW_20251231.nc ...  -> SUKSES!\n",
            "\n",
            "==============================\n",
            "SELESAI. Cek folder '/content/drive/MyDrive/MAGANG/CORAL/02_Clip_lombok' di Google Drive kamu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Hasil(opsional)"
      ],
      "metadata": {
        "id": "oyXGEE8AZpTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip folder output\n",
        "shutil.make_archive(\"/content/drive/MyDrive/MAGANG/CORAL/02_Clip_lombok\", 'zip', output_dir)\n",
        "\n",
        "# Download ke laptop\n",
        "files.download(\"/content/drive/MyDrive/MAGANG/CORAL/02_Clip_lombok.zip\")"
      ],
      "metadata": {
        "id": "d2eew2cUZj3p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "30ece11c-1d86-4d85-ffc9-7d32195dab74"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7c4d320d-e4d9-4dc4-9662-4bf1e0b32694\", \"02_Clip_lombok.zip\", 38719)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4 Clipping (Masked Site)\n",
        "memotong data menggunakan Shapefile (Peta Batas Kawasan) agar data yang diambil benar-benar hanya yang berada di dalam kawasan konservasi:\n",
        "\n",
        "\n",
        "1.   Gili Matra (Gili Meno, Air, Trawangan)\n",
        "2.   Gita Nada (Gili Tangkong, Nanggu, Sudak)\n",
        "3.  Nusa Penida\n",
        "\n",
        "\n",
        "Output Akhir:\n",
        "File berformat .xyz (Text file berisi Longitude, Latitude, Value) yang siap di-plot atau dianalisis lebih lanjut. File ini juga akan otomatis di-ZIP agar mudah di-download."
      ],
      "metadata": {
        "id": "32rVMziAeVhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup & Install Library"
      ],
      "metadata": {
        "id": "XY8Y31lrZ15k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install Library GeoSpasial\n",
        "!pip install geopandas rioxarray netCDF4\n",
        "\n",
        "# 2. Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "import xarray as xr\n",
        "import rioxarray\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "# Abaikan warning\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- KONFIGURASI PATH UTAMA ---\n",
        "# Path dasar project kamu di Drive\n",
        "base_project_dir = \"/content/drive/MyDrive/MAGANG/CORAL\"\n",
        "\n",
        "# Folder Input (.nc yang sudah di-clip Lombok)\n",
        "input_nc_dir = os.path.join(base_project_dir, \"02_Clip_lombok\")\n",
        "\n",
        "# Folder Output (.xyz)\n",
        "output_dir = os.path.join(base_project_dir, \"03_Masking_Site\")\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(f\"üìÇ Input: {input_nc_dir}\")\n",
        "print(f\"üìÇ Output: {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMCj02t8eUVW",
        "outputId": "97b25026-4390-41a0-ea0d-00937bb191dc",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Requirement already satisfied: rioxarray in /usr/local/lib/python3.12/dist-packages (0.21.0)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.12/dist-packages (1.7.4)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.12.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas) (25.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (3.7.2)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.1.2)\n",
            "Requirement already satisfied: rasterio>=1.4.3 in /usr/local/lib/python3.12/dist-packages (from rioxarray) (1.5.0)\n",
            "Requirement already satisfied: xarray<2025.12,>=2024.7.0 in /usr/local/lib/python3.12/dist-packages (from rioxarray) (2025.11.0)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.12/dist-packages (from netCDF4) (1.6.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netCDF4) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (25.4.0)\n",
            "Requirement already satisfied: click!=8.2.*,>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (0.7.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (3.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.17.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üìÇ Input: /content/drive/MyDrive/MAGANG/CORAL/02_Clip_lombok\n",
            "üìÇ Output: /content/drive/MyDrive/MAGANG/CORAL/03_Masking_Site\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasi Shapefile (PENTING)"
      ],
      "metadata": {
        "id": "Bjp8oEvOX84U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- KONFIGURASI LOKASI SHAPEFILE ---\n",
        "\n",
        "# Sesuaikan path ini dengan lokasi folder \"basemap\" kamu di Google Drive\n",
        "# Asumsi: Kamu mengupload folder 'bahan' ke dalam folder 'CORAL' di Drive (di sini folder site namanya SHP_SITE)\n",
        "shp_base_dir = os.path.join(base_project_dir, \"SHP_SITE\")\n",
        "\n",
        "# Cek apakah folder shp ada?\n",
        "if not os.path.exists(shp_base_dir):\n",
        "    print(f\"‚ö†Ô∏è PERINGATAN: Folder Shapefile tidak ditemukan di:\\n{shp_base_dir}\")\n",
        "    print(\"üëâ Tolong edit variabel 'shp_base_dir' di atas sesuai lokasi folder shp di Drive kamu.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Folder Shapefile ditemukan!\")\n",
        "\n",
        "# Dictionary Shapefile\n",
        "# Kita gabungkan folder dasar dengan nama filenya\n",
        "regions = {\n",
        "    \"gm\": os.path.join(shp_base_dir, \"gili_matra_buffer_5km.shp\"),\n",
        "    \"gn\": os.path.join(shp_base_dir, \"gita_nada_buffer_5km.shp\"),\n",
        "    \"np\": os.path.join(shp_base_dir, \"nusa_penida_buffer_5km.shp\")\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxXnou6TXrG8",
        "outputId": "04d1ae11-3a90-44ae-b502-7dd259d93cff",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Folder Shapefile ditemukan!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jalankan Proses Masking"
      ],
      "metadata": {
        "id": "q1yBTphoYBOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masking_process_colab():\n",
        "    print(\"--- PROSES MASKING SHAPEFILE KE XYZ (DRIVE) ---\")\n",
        "\n",
        "    # Ambil semua file .nc\n",
        "    nc_files = glob.glob(os.path.join(input_nc_dir, \"*.nc\"))\n",
        "\n",
        "    if not nc_files:\n",
        "        print(\"[ERROR] Tidak ada file .nc di folder input! Cek path folder 02_Clip_lombok.\")\n",
        "        return\n",
        "\n",
        "    # Loop setiap file Raster (.nc)\n",
        "    for i, nc_path in enumerate(nc_files, 1):\n",
        "        filename_full = os.path.basename(nc_path)\n",
        "        filename_no_ext = os.path.splitext(filename_full)[0] # Hilangkan .nc\n",
        "\n",
        "        # Filter file yang mau diolah\n",
        "        # Kita hanya ingin mengolah file yang namanya \"Clip_Lombok_...\" atau file NOAA asli\n",
        "        # Skip jika file itu file sisa/temp\n",
        "        if filename_full.startswith(\"Layer_\"):\n",
        "            continue\n",
        "\n",
        "        print(f\"[{i}/{len(nc_files)}] Memproses: {filename_full}\")\n",
        "\n",
        "        try:\n",
        "            # 1. Buka Raster\n",
        "            ds = xr.open_dataset(nc_path)\n",
        "\n",
        "            # Deteksi nama koordinat\n",
        "            if 'lat' in ds.coords:\n",
        "                ds = ds.rio.set_spatial_dims(\"lon\", \"lat\")\n",
        "                x_name, y_name = 'lon', 'lat'\n",
        "            elif 'latitude' in ds.coords:\n",
        "                ds = ds.rio.set_spatial_dims(\"longitude\", \"latitude\")\n",
        "                x_name, y_name = 'longitude', 'latitude'\n",
        "            else:\n",
        "                print(\"   -> Skip (Koordinat tidak dikenali)\")\n",
        "                continue\n",
        "\n",
        "            # Set CRS & Sorting (Agar aman saat clipping)\n",
        "            ds = ds.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
        "            ds = ds.sortby([y_name, x_name])\n",
        "\n",
        "            # Loop setiap Wilayah (Shapefile)\n",
        "            for code, shp_path in regions.items():\n",
        "                # Cek dulu apakah file shp beneran ada\n",
        "                if not os.path.exists(shp_path):\n",
        "                    print(f\"   -> [SKIP] File SHP tidak ditemukan: {shp_path}\")\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # 2. Buka Shapefile\n",
        "                    gdf = gpd.read_file(shp_path)\n",
        "\n",
        "                    # Samakan CRS\n",
        "                    if gdf.crs != ds.rio.crs:\n",
        "                        gdf = gdf.to_crs(ds.rio.crs)\n",
        "\n",
        "                    # 3. Lakukan Clipping (Masking)\n",
        "                    try:\n",
        "                        clipped = ds.rio.clip(gdf.geometry, gdf.crs, drop=True)\n",
        "                    except Exception as e_clip:\n",
        "                        # Kadang error jika tidak ada overlap sama sekali\n",
        "                        print(f\"   -> {code}: Tidak overlap/diluar area raster.\")\n",
        "                        continue\n",
        "\n",
        "                    # 4. Konversi ke Format XYZ\n",
        "                    df = clipped.to_dataframe().reset_index()\n",
        "\n",
        "                    # Cari variabel data\n",
        "                    ignore_cols = [x_name, y_name, 'time', 'spatial_ref', 'crs', 'band']\n",
        "                    data_vars = [col for col in df.columns if col not in ignore_cols]\n",
        "\n",
        "                    if not data_vars:\n",
        "                        print(f\"   -> Warning: Tidak ada data variabel di {code}\")\n",
        "                        continue\n",
        "\n",
        "                    target_var = data_vars[0]\n",
        "\n",
        "                    # Filter X, Y, Z dan drop NaN\n",
        "                    xyz_df = df[[x_name, y_name, target_var]].dropna()\n",
        "\n",
        "                    if xyz_df.empty:\n",
        "                        print(f\"   -> {code}: Hasil Kosong (Semua NaN)\")\n",
        "                        continue\n",
        "\n",
        "                    # 5. Simpan ke .XYZ di Drive\n",
        "                    # Nama file output sesuai request\n",
        "                    output_filename = f\"{code}_{filename_no_ext}.xyz\"\n",
        "                    output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "                    xyz_df.to_csv(output_path, sep=' ', header=False, index=False)\n",
        "\n",
        "                    print(f\"   -> OK: {output_filename}\")\n",
        "\n",
        "                except Exception as e_shp:\n",
        "                    print(f\"   -> Error wilayah {code}: {e_shp}\")\n",
        "\n",
        "            ds.close()\n",
        "\n",
        "        except Exception as e_file:\n",
        "            print(f\"   -> Gagal membuka file: {e_file}\")\n",
        "\n",
        "    print(\"\\n--- SELESAI SEMUA ---\")\n",
        "    print(f\"Cek folder output di: {output_dir}\")\n",
        "\n",
        "# Jalankan Fungsi\n",
        "masking_process_colab()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4__mCXPFXto_",
        "outputId": "cc9bf95e-de98-40bb-cb98-89398a03eaa0",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- PROSES MASKING SHAPEFILE KE XYZ (DRIVE) ---\n",
            "[1/5] Memproses: Clip_Lombok_NOAA_SST_20251202.nc\n",
            "   -> OK: gm_Clip_Lombok_NOAA_SST_20251202.xyz\n",
            "   -> OK: gn_Clip_Lombok_NOAA_SST_20251202.xyz\n",
            "   -> OK: np_Clip_Lombok_NOAA_SST_20251202.xyz\n",
            "[2/5] Memproses: Clip_Lombok_NOAA_SST_20251231.nc\n",
            "   -> OK: gm_Clip_Lombok_NOAA_SST_20251231.xyz\n",
            "   -> OK: gn_Clip_Lombok_NOAA_SST_20251231.xyz\n",
            "   -> OK: np_Clip_Lombok_NOAA_SST_20251231.xyz\n",
            "[3/5] Memproses: Clip_Lombok_NOAA_SSTA_20251231.nc\n",
            "   -> OK: gm_Clip_Lombok_NOAA_SSTA_20251231.xyz\n",
            "   -> OK: gn_Clip_Lombok_NOAA_SSTA_20251231.xyz\n",
            "   -> OK: np_Clip_Lombok_NOAA_SSTA_20251231.xyz\n",
            "[4/5] Memproses: Clip_Lombok_NOAA_HS_20251231.nc\n",
            "   -> OK: gm_Clip_Lombok_NOAA_HS_20251231.xyz\n",
            "   -> OK: gn_Clip_Lombok_NOAA_HS_20251231.xyz\n",
            "   -> OK: np_Clip_Lombok_NOAA_HS_20251231.xyz\n",
            "[5/5] Memproses: Clip_Lombok_NOAA_DHW_20251231.nc\n",
            "   -> OK: gm_Clip_Lombok_NOAA_DHW_20251231.xyz\n",
            "   -> OK: gn_Clip_Lombok_NOAA_DHW_20251231.xyz\n",
            "   -> OK: np_Clip_Lombok_NOAA_DHW_20251231.xyz\n",
            "\n",
            "--- SELESAI SEMUA ---\n",
            "Cek folder output di: /content/drive/MyDrive/MAGANG/CORAL/03_Masking_Site\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Hasil"
      ],
      "metadata": {
        "id": "as9MLpCpYHs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip folder output\n",
        "shutil.make_archive(\"/content/drive/MyDrive/MAGANG/CORAL/03_Masking_Site\", 'zip', output_dir)\n",
        "\n",
        "# Download\n",
        "files.download(\"/content/drive/MyDrive/MAGANG/CORAL/03_Masking_Site.zip\")"
      ],
      "metadata": {
        "id": "L3ScNqYoX0GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NOAA Climatology"
      ],
      "metadata": {
        "id": "gjNnPKoLdZRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tahap 1: Download & Clipping Data Climatology\n",
        "**Tujuan:** Mengunduh data Climatology NOAA dan memotongnya sesuai area Shapefile.\n",
        "\n",
        "‚ö†Ô∏è **WAJIB CEK SEBELUM RUN:**\n",
        "Pastikan Anda sudah mengupload file Shapefile lengkap (`.shp`, `.shx`, `.dbf`, `.prj`) ke dalam folder:\n",
        "`.../MAGANG/CORAL/01_climatology/SHP_SITE/`\n",
        "\n",
        "Jika folder kosong, script akan error atau men-skip proses clipping."
      ],
      "metadata": {
        "id": "nyxo0Y4VjdVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jalankan ini dulu untuk menginstall library yang dibutuhkan di Colab\n",
        "!pip install xarray rioxarray geopandas netCDF4"
      ],
      "metadata": {
        "id": "zRlmZWixdYQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fb1086c4-3e09-4e11-9b1b-4e4bfcf97014"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (2025.11.0)\n",
            "Requirement already satisfied: rioxarray in /usr/local/lib/python3.12/dist-packages (0.21.0)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.12/dist-packages (1.7.4)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from xarray) (2.0.2)\n",
            "Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.12/dist-packages (from xarray) (25.0)\n",
            "Requirement already satisfied: pandas>=2.2 in /usr/local/lib/python3.12/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: rasterio>=1.4.3 in /usr/local/lib/python3.12/dist-packages (from rioxarray) (1.5.0)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.12/dist-packages (from rioxarray) (3.7.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.12.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.1.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.12/dist-packages (from netCDF4) (1.6.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netCDF4) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2025.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (25.4.0)\n",
            "Requirement already satisfied: click!=8.2.*,>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (0.7.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (3.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2->xarray) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import glob\n",
        "import warnings\n",
        "import xarray as xr\n",
        "import rioxarray\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Abaikan warning\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. KONFIGURASI PATH (GOOGLE DRIVE)\n",
        "# ==========================================\n",
        "\n",
        "# Path disesuaikan untuk Google Colab\n",
        "# Pastikan folder 'MAGANG' ada di 'My Drive' kamu\n",
        "base_dir = \"/content/drive/MyDrive/MAGANG/CORAL/01_climatology\"\n",
        "\n",
        "# Folder Output & Input\n",
        "input_global_dir = os.path.join(base_dir, \"00_Raw_Climatology\")\n",
        "output_xyz_dir = os.path.join(base_dir, \"03_Masking_Site_Clim\")\n",
        "shp_base_dir = os.path.join(base_dir, \"SHP_SITE\")\n",
        "\n",
        "# Buat folder jika belum ada\n",
        "os.makedirs(input_global_dir, exist_ok=True)\n",
        "os.makedirs(output_xyz_dir, exist_ok=True)\n",
        "\n",
        "# Link NOAA (Climatology)\n",
        "BASE_URL_NOAA = \"https://www.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1_op/climatology/nc/\"\n",
        "\n",
        "# Daftar File\n",
        "target_files = [\n",
        "    \"ct5km_climatology_v3.1.nc\"\n",
        "]\n",
        "\n",
        "# Koordinat & Shapefile\n",
        "lat_min, lat_max = -9, -8\n",
        "lon_min, lon_max = 115.2, 116.2\n",
        "\n",
        "# Pastikan file .shp ini BENAR-BENAR ADA di folder Google Drive kamu\n",
        "regions = {\n",
        "    \"gm\": os.path.join(shp_base_dir, \"gili_matra_buffer_5km.shp\"),\n",
        "    \"gn\": os.path.join(shp_base_dir, \"gita_nada_buffer_5km.shp\"),\n",
        "    \"np\": os.path.join(shp_base_dir, \"nusa_penida_buffer_5km.shp\")\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. FUNGSI DOWNLOADER\n",
        "# ==========================================\n",
        "def download_noaa_data():\n",
        "    print(\"--- CEK KETERSEDIAAN DATA CLIMATOLOGY ---\")\n",
        "\n",
        "    for filename in target_files:\n",
        "        file_path = os.path.join(input_global_dir, filename)\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"‚úÖ {filename} sudah ada di Drive. Skip download.\")\n",
        "        else:\n",
        "            url = BASE_URL_NOAA + filename\n",
        "            print(f\"‚¨áÔ∏è Sedang mendownload: {filename} ...\")\n",
        "            print(f\"   Sumber: {url}\")\n",
        "            print(f\"   Target: {file_path}\")\n",
        "\n",
        "            try:\n",
        "                response = requests.get(url, stream=True)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "\n",
        "                print(\"   -> Download Selesai!\")\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå GAGAL Download: {e}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. FUNGSI PROCESSING\n",
        "# ==========================================\n",
        "def process_climatology():\n",
        "    print(\"\\n--- MULAI PEMROSESAN DATA ---\")\n",
        "\n",
        "    # Cek apakah file ada\n",
        "    raw_files = glob.glob(os.path.join(input_global_dir, \"*.nc\"))\n",
        "\n",
        "    if not raw_files:\n",
        "        print(f\"ERROR: Tidak ada file .nc di {input_global_dir}\")\n",
        "        print(\"Pastikan download berhasil atau upload manual ke Google Drive.\")\n",
        "        return\n",
        "\n",
        "    for i, file_path in enumerate(raw_files, 1):\n",
        "        filename = os.path.basename(file_path)\n",
        "        filename_no_ext = os.path.splitext(filename)[0]\n",
        "\n",
        "        print(f\"\\n[{i}/{len(raw_files)}] Memproses: {filename}\")\n",
        "\n",
        "        try:\n",
        "            ds = xr.open_dataset(file_path)\n",
        "\n",
        "            if 'lat' in ds.coords:\n",
        "                ds = ds.rename({'lat': 'latitude', 'lon': 'longitude'})\n",
        "\n",
        "            ds = ds.sortby(['latitude', 'longitude'])\n",
        "\n",
        "            # Handle slicing\n",
        "            slice_lat = slice(lat_min, lat_max) if ds.latitude[0] < ds.latitude[-1] else slice(lat_max, lat_min)\n",
        "            ds_lombok = ds.sel(latitude=slice_lat, longitude=slice(lon_min, lon_max))\n",
        "\n",
        "            if ds_lombok.dims['latitude'] == 0 or ds_lombok.dims['longitude'] == 0:\n",
        "                print(\" -> GAGAL: Area Lombok kosong (Koordinat slicing mungkin salah).\")\n",
        "                continue\n",
        "\n",
        "            ds_lombok = ds_lombok.rio.set_spatial_dims(\"longitude\", \"latitude\")\n",
        "            ds_lombok = ds_lombok.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
        "\n",
        "            for code, shp_path in regions.items():\n",
        "                if not os.path.exists(shp_path):\n",
        "                    print(f\"    -> [SKIP] SHP {code} tidak ditemukan di: {shp_path}\")\n",
        "                    continue\n",
        "\n",
        "                # Baca SHP\n",
        "                gdf = gpd.read_file(shp_path)\n",
        "                if gdf.crs != ds_lombok.rio.crs:\n",
        "                    gdf = gdf.to_crs(ds_lombok.rio.crs)\n",
        "\n",
        "                try:\n",
        "                    clipped = ds_lombok.rio.clip(gdf.geometry, gdf.crs, drop=True)\n",
        "                    df = clipped.to_dataframe().reset_index()\n",
        "\n",
        "                    ignore_cols = ['latitude', 'longitude', 'spatial_ref', 'crs', 'band', 'time']\n",
        "                    data_vars = [c for c in df.columns if c not in ignore_cols and c != 'month']\n",
        "\n",
        "                    if not data_vars: continue\n",
        "                    target_var = data_vars[0]\n",
        "\n",
        "                    # Climatology biasanya memiliki variabel 'month' (1-12)\n",
        "                    if 'month' in df.columns:\n",
        "                        unique_months = df['month'].unique()\n",
        "                        for m in unique_months:\n",
        "                            df_month = df[df['month'] == m]\n",
        "                            xyz = df_month[['longitude', 'latitude', target_var]].dropna()\n",
        "                            if xyz.empty: continue\n",
        "\n",
        "                            # Output XYZ per bulan\n",
        "                            out_name = f\"{code}_{filename_no_ext}_bulan_{int(m)}.xyz\"\n",
        "                            out_path = os.path.join(output_xyz_dir, out_name)\n",
        "                            xyz.to_csv(out_path, sep=' ', header=False, index=False)\n",
        "                        print(f\"    -> {code}: OK (12 Bulan)\")\n",
        "                    else:\n",
        "                        # Jika data statis (bukan bulanan)\n",
        "                        xyz = df[['longitude', 'latitude', target_var]].dropna()\n",
        "                        if xyz.empty: continue\n",
        "\n",
        "                        out_name = f\"{code}_{filename_no_ext}.xyz\"\n",
        "                        out_path = os.path.join(output_xyz_dir, out_name)\n",
        "                        xyz.to_csv(out_path, sep=' ', header=False, index=False)\n",
        "                        print(f\"    -> {code}: OK (Statis)\")\n",
        "\n",
        "                except Exception as e_site:\n",
        "                    print(f\"    -> Error Clipping {code}: {e_site}\")\n",
        "\n",
        "            ds.close()\n",
        "            ds_lombok.close()\n",
        "\n",
        "        except Exception as e_file:\n",
        "            print(f\" -> ERROR Membuka File {filename}: {e_file}\")\n",
        "\n",
        "    print(\"\\n=== SELESAI SEMUA. CEK GOOGLE DRIVE KAMU ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Jalankan Downloader\n",
        "    download_noaa_data()\n",
        "    # Jalankan Processing\n",
        "    process_climatology()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6U1YdAGJtHnv",
        "outputId": "d52b32d0-e5e1-4db7-df22-6ea3bac2bca7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--- CEK KETERSEDIAAN DATA CLIMATOLOGY ---\n",
            "‚¨áÔ∏è Sedang mendownload: ct5km_climatology_v3.1.nc ...\n",
            "   Sumber: https://www.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1_op/climatology/nc/ct5km_climatology_v3.1.nc\n",
            "   Target: /content/drive/MyDrive/MAGANG/CORAL/01_climatology/00_Raw_Climatology/ct5km_climatology_v3.1.nc\n",
            "   -> Download Selesai!\n",
            "\n",
            "--- MULAI PEMROSESAN DATA ---\n",
            "\n",
            "[1/1] Memproses: ct5km_climatology_v3.1.nc\n",
            "    -> gm: OK (Statis)\n",
            "    -> gn: OK (Statis)\n",
            "    -> np: OK (Statis)\n",
            "\n",
            "=== SELESAI SEMUA. CEK GOOGLE DRIVE KAMU ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tahap 2: Perhitungan Statistik Climatology (MMM)\n",
        "**Tujuan:** Menghitung rata-rata bulanan dan nilai MMM (Maximum Monthly Mean) yang menjadi ambang batas bleaching.\n",
        "\n",
        "**Output:**\n",
        "Script ini akan menghasilkan file teks penting bernama: **`mmm_mean_site_FINAL.txt`**.\n",
        "Pastikan file ini berhasil muncul di folder `01_climatology` sebelum lanjut ke tahap akhir."
      ],
      "metadata": {
        "id": "tGu8iYTitnCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import rioxarray\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Abaikan warning\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. KONFIGURASI PATH (GOOGLE DRIVE)\n",
        "# ==========================================\n",
        "\n",
        "# Sesuaikan path ini dengan lokasi di Google Drive kamu\n",
        "base_dir = \"/content/drive/MyDrive/MAGANG/CORAL/01_climatology\"\n",
        "\n",
        "# File input (Pastikan file ini sudah didownload oleh script sebelumnya)\n",
        "input_nc = os.path.join(base_dir, \"00_Raw_Climatology\", \"ct5km_climatology_v3.1.nc\")\n",
        "shp_base_dir = os.path.join(base_dir, \"SHP_SITE\")\n",
        "\n",
        "# File Output Laporan\n",
        "output_report = os.path.join(base_dir, \"mmm_mean_site_FINAL.txt\")\n",
        "\n",
        "# Koordinat Kotak Lombok (Slicing agar RAM Aman)\n",
        "lat_min, lat_max = -9.2, -8.2\n",
        "lon_min, lon_max = 115.3, 116.3\n",
        "\n",
        "# Definisi Lokasi Shapefile\n",
        "regions = {\n",
        "    \"gm\": os.path.join(shp_base_dir, \"gili_matra_buffer_5km.shp\"),\n",
        "    \"gn\": os.path.join(shp_base_dir, \"gita_nada_buffer_5km.shp\"),\n",
        "    \"np\": os.path.join(shp_base_dir, \"nusa_penida_buffer_5km.shp\")\n",
        "}\n",
        "\n",
        "# DAFTAR NAMA VARIABEL BULAN (Sesuai standar NOAA CRW v3.1)\n",
        "month_vars = [\n",
        "    'sst_clim_january', 'sst_clim_february', 'sst_clim_march',\n",
        "    'sst_clim_april', 'sst_clim_may', 'sst_clim_june',\n",
        "    'sst_clim_july', 'sst_clim_august', 'sst_clim_september',\n",
        "    'sst_clim_october', 'sst_clim_november', 'sst_clim_december'\n",
        "]\n",
        "\n",
        "def calculate_site_climatology():\n",
        "    # Cek keberadaan file NetCDF\n",
        "    if not os.path.exists(input_nc):\n",
        "        print(f\"‚ùå File Climatology tidak ditemukan di: {input_nc}\")\n",
        "        print(\"   Pastikan kamu sudah menjalankan script download sebelumnya.\")\n",
        "        return\n",
        "\n",
        "    print(f\"üìÇ Membuka dataset: {os.path.basename(input_nc)}\")\n",
        "\n",
        "    try:\n",
        "        ds = xr.open_dataset(input_nc)\n",
        "\n",
        "        # --- TAHAP 1: NORMALISASI & SLICING ---\n",
        "        # Rename koordinat jika perlu\n",
        "        if 'lat' in ds.coords:\n",
        "            ds = ds.rename({'lat': 'latitude', 'lon': 'longitude'})\n",
        "        ds = ds.sortby(['latitude', 'longitude'])\n",
        "\n",
        "        print(\"‚úÇÔ∏è  Memotong area Lombok (Saving RAM)...\")\n",
        "\n",
        "        # Slicing Spasial (Handle urutan latitude ascending/descending)\n",
        "        if ds.latitude[0] > ds.latitude[-1]:\n",
        "            ds_lombok = ds.sel(latitude=slice(lat_max, lat_min), longitude=slice(lon_min, lon_max))\n",
        "        else:\n",
        "            ds_lombok = ds.sel(latitude=slice(lat_min, lat_max), longitude=slice(lon_min, lon_max))\n",
        "\n",
        "        # Set CRS (Coordinate Reference System)\n",
        "        ds_lombok = ds_lombok.rio.set_spatial_dims(\"longitude\", \"latitude\").rio.write_crs(\"EPSG:4326\")\n",
        "\n",
        "        results = []\n",
        "        print(\"\\n--- MULAI PERHITUNGAN SITE ---\")\n",
        "\n",
        "        for code, shp_path in regions.items():\n",
        "            # Cek apakah shapefile ada\n",
        "            if not os.path.exists(shp_path):\n",
        "                print(f\"‚ö†Ô∏è  Skip {code}: Shapefile tidak ditemukan ({shp_path})\")\n",
        "                continue\n",
        "\n",
        "            print(f\"üîÑ Processing Site: {code.upper()}\")\n",
        "\n",
        "            try:\n",
        "                gdf = gpd.read_file(shp_path)\n",
        "\n",
        "                # Samakan CRS Shapefile dengan NetCDF\n",
        "                if gdf.crs != ds_lombok.rio.crs:\n",
        "                    gdf = gdf.to_crs(ds_lombok.rio.crs)\n",
        "\n",
        "                # 1. Clip NetCDF sesuai bentuk Shapefile\n",
        "                clipped = ds_lombok.rio.clip(gdf.geometry, gdf.crs, drop=True)\n",
        "\n",
        "                site_means = []\n",
        "\n",
        "                # 2. LOOP 12 BULAN\n",
        "                for var_name in month_vars:\n",
        "                    if var_name in clipped.data_vars:\n",
        "                        # Hitung rata-rata spasial (spatial mean) area tersebut\n",
        "                        val = clipped[var_name].mean(dim=['latitude', 'longitude'], skipna=True).item()\n",
        "                        site_means.append(val)\n",
        "                    else:\n",
        "                        print(f\"   ‚ö†Ô∏è Warning: Variabel {var_name} tidak ada.\")\n",
        "                        site_means.append(np.nan)\n",
        "\n",
        "                # 3. Hitung MMM (Maximum Monthly Mean)\n",
        "                clean_means = [x for x in site_means if not np.isnan(x)]\n",
        "\n",
        "                if len(clean_means) == 12:\n",
        "                    mmm_value = max(clean_means) # Nilai tertinggi dari 12 bulan\n",
        "\n",
        "                    results.append({\n",
        "                        'name': code.upper(),\n",
        "                        'mmm': mmm_value,\n",
        "                        'means': clean_means\n",
        "                    })\n",
        "                    print(f\"   ‚úÖ OK. MMM: {mmm_value:.4f}\")\n",
        "                else:\n",
        "                    print(\"   ‚ùå Gagal: Data bulan tidak lengkap.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå Error pada {code}: {e}\")\n",
        "\n",
        "        # --- TAHAP 3: SIMPAN OUTPUT ---\n",
        "        if results:\n",
        "            with open(output_report, 'w') as f:\n",
        "                for res in results:\n",
        "                    f.write(f\"SITE: {res['name']}\\n\")\n",
        "                    f.write(\"Averaged Maximum Monthly Mean:\\n\")\n",
        "                    f.write(f\"{res['mmm']:.4f}\\n\\n\")\n",
        "\n",
        "                    f.write(\"Averaged Monthly Mean (Jan-Dec):\\n\")\n",
        "                    # Join list menjadi string\n",
        "                    means_str = \" \".join([f\"{val:.4f}\" for val in res['means']])\n",
        "                    f.write(f\"{means_str}\\n\")\n",
        "\n",
        "                    f.write(\"\\n\" + \"=\"*40 + \"\\n\\n\")\n",
        "\n",
        "            print(f\"\\nüéâ SELESAI! Laporan tersimpan di:\\n   {output_report}\")\n",
        "            print(\"   Kamu bisa menggunakan file ini untuk script Final Report nanti.\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è Tidak ada hasil yang disimpan (Cek apakah Shapefile/NetCDF valid).\")\n",
        "\n",
        "        ds.close()\n",
        "        ds_lombok.close()\n",
        "\n",
        "    except Exception as e_open:\n",
        "        print(f\"CRITICAL ERROR: {e_open}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    calculate_site_climatology()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muoLRt3guTaS",
        "outputId": "8318eb80-5237-4e4f-8c59-4bba2c41d8d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üìÇ Membuka dataset: ct5km_climatology_v3.1.nc\n",
            "‚úÇÔ∏è  Memotong area Lombok (Saving RAM)...\n",
            "\n",
            "--- MULAI PERHITUNGAN SITE ---\n",
            "üîÑ Processing Site: GM\n",
            "   ‚úÖ OK. MMM: 29.0514\n",
            "üîÑ Processing Site: GN\n",
            "   ‚úÖ OK. MMM: 28.6450\n",
            "üîÑ Processing Site: NP\n",
            "   ‚úÖ OK. MMM: 28.4726\n",
            "\n",
            "üéâ SELESAI! Laporan tersimpan di:\n",
            "   /content/drive/MyDrive/MAGANG/CORAL/01_climatology/mmm_mean_site_FINAL.txt\n",
            "   Kamu bisa menggunakan file ini untuk script Final Report nanti.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 90th percentile Coral Bleaching"
      ],
      "metadata": {
        "id": "MCPqf7I-uvLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library geospatial yang diperlukan\n",
        "!pip install xarray rioxarray geopandas netCDF4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnaAh7f5vXfQ",
        "outputId": "001ccea1-c1eb-43f6-851e-d10453aba915"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (2025.11.0)\n",
            "Requirement already satisfied: rioxarray in /usr/local/lib/python3.12/dist-packages (0.21.0)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.12/dist-packages (1.7.4)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from xarray) (2.0.2)\n",
            "Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.12/dist-packages (from xarray) (25.0)\n",
            "Requirement already satisfied: pandas>=2.2 in /usr/local/lib/python3.12/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: rasterio>=1.4.3 in /usr/local/lib/python3.12/dist-packages (from rioxarray) (1.5.0)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.12/dist-packages (from rioxarray) (3.7.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.12.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.1.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.12/dist-packages (from netCDF4) (1.6.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netCDF4) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2025.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (25.4.0)\n",
            "Requirement already satisfied: click!=8.2.*,>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (0.7.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio>=1.4.3->rioxarray) (3.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2->xarray) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import re\n",
        "from collections import deque\n",
        "import xarray as xr\n",
        "import rioxarray\n",
        "import geopandas as gpd\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Abaikan warning\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. KONFIGURASI PATH & FILE (GOOGLE DRIVE)\n",
        "# ==============================================================================\n",
        "\n",
        "# --- TENTUKAN ROOT FOLDER PROYEK ---\n",
        "# Sesuaikan 'MAGANG/CORAL/output' dengan lokasi folder kamu di Drive\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/MAGANG/CORAL\"\n",
        "\n",
        "# --- KONFIGURASI CLIMATOLOGY (INPUT) ---\n",
        "# Folder 01_climatology ada di dalam PROJECT_ROOT\n",
        "base_dir_clim = os.path.join(PROJECT_ROOT, \"01_climatology\")\n",
        "\n",
        "input_nc = os.path.join(base_dir_clim, \"00_Raw_Climatology\", \"ct5km_climatology_v3.1.nc\")\n",
        "shp_base_dir = os.path.join(base_dir_clim, \"SHP_SITE\")\n",
        "\n",
        "# Mapping Kode Wilayah ke File Shapefile\n",
        "regions_shp = {\n",
        "    \"GM\": os.path.join(shp_base_dir, \"gili_matra_buffer_5km.shp\"),\n",
        "    \"GN\": os.path.join(shp_base_dir, \"gita_nada_buffer_5km.shp\"),\n",
        "    \"NP\": os.path.join(shp_base_dir, \"nusa_penida_buffer_5km.shp\")\n",
        "}\n",
        "\n",
        "# --- KONFIGURASI DATA HARIAN (INPUT) ---\n",
        "# Pastikan folder \"03_Masking_Site\" ada di dalam PROJECT_ROOT atau sesuaikan path-nya\n",
        "INPUT_FOLDER_XYZ = os.path.join(PROJECT_ROOT, \"03_Masking_Site\")\n",
        "\n",
        "# --- KONFIGURASI OUTPUT ---\n",
        "OUTPUT_FOLDER = os.path.join(PROJECT_ROOT, \"NOAA_Final_Reports_Integrated\")\n",
        "\n",
        "# Variabel Bulan dalam NetCDF\n",
        "month_vars = [\n",
        "    'sst_clim_january', 'sst_clim_february', 'sst_clim_march',\n",
        "    'sst_clim_april', 'sst_clim_may', 'sst_clim_june',\n",
        "    'sst_clim_july', 'sst_clim_august', 'sst_clim_september',\n",
        "    'sst_clim_october', 'sst_clim_november', 'sst_clim_december'\n",
        "]\n",
        "\n",
        "# Koordinat Slicing (Lombok Area)\n",
        "lat_min, lat_max = -9.2, -8.2\n",
        "lon_min, lon_max = 115.3, 116.3\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. MODUL CLIMATOLOGY (XARRAY & GEOPANDAS)\n",
        "# ==============================================================================\n",
        "def calculate_climatology_data():\n",
        "    \"\"\"\n",
        "    Menghitung MMM dan Monthly Mean dari file NetCDF menggunakan Shapefile.\n",
        "    Mengembalikan dictionary berisi data klimatologi per site.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"   MEMULAI PERHITUNGAN CLIMATOLOGY (NetCDF)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if not os.path.exists(input_nc):\n",
        "        print(f\"‚ùå File NC tidak ditemukan: {input_nc}\")\n",
        "        print(\"   Pastikan path di Google Drive sudah benar.\")\n",
        "        return {}\n",
        "\n",
        "    # Buka Dataset\n",
        "    try:\n",
        "        ds = xr.open_dataset(input_nc)\n",
        "\n",
        "        # Normalisasi nama dimensi\n",
        "        if 'lat' in ds.coords: ds = ds.rename({'lat': 'latitude', 'lon': 'longitude'})\n",
        "        ds = ds.sortby(['latitude', 'longitude'])\n",
        "\n",
        "        # Slicing Area Lombok (Hemat RAM)\n",
        "        print(\"‚úÇÔ∏è  Memotong area Lombok...\")\n",
        "        if ds.latitude[0] > ds.latitude[-1]:\n",
        "            ds_lombok = ds.sel(latitude=slice(lat_max, lat_min), longitude=slice(lon_min, lon_max))\n",
        "        else:\n",
        "            ds_lombok = ds.sel(latitude=slice(lat_min, lat_max), longitude=slice(lon_min, lon_max))\n",
        "\n",
        "        ds_lombok = ds_lombok.rio.set_spatial_dims(\"longitude\", \"latitude\").rio.write_crs(\"EPSG:4326\")\n",
        "\n",
        "        clim_results = {}\n",
        "\n",
        "        for code, shp_path in regions_shp.items():\n",
        "            if not os.path.exists(shp_path):\n",
        "                print(f\"‚ö†Ô∏è  Shapefile tidak ditemukan untuk {code}: {shp_path}\")\n",
        "                continue\n",
        "\n",
        "            print(f\"üîÑ Processing Climatology: {code}\")\n",
        "            gdf = gpd.read_file(shp_path)\n",
        "\n",
        "            # Samakan CRS\n",
        "            if gdf.crs != ds_lombok.rio.crs:\n",
        "                gdf = gdf.to_crs(ds_lombok.rio.crs)\n",
        "\n",
        "            try:\n",
        "                # Clip NetCDF dengan Shapefile\n",
        "                clipped = ds_lombok.rio.clip(gdf.geometry, gdf.crs, drop=True)\n",
        "\n",
        "                site_means = []\n",
        "                # Loop 12 Bulan\n",
        "                for var_name in month_vars:\n",
        "                    if var_name in clipped.data_vars:\n",
        "                        val = clipped[var_name].mean(dim=['latitude', 'longitude'], skipna=True).item()\n",
        "                        site_means.append(val)\n",
        "                    else:\n",
        "                        site_means.append(np.nan)\n",
        "\n",
        "                clean_means = [x for x in site_means if not np.isnan(x)]\n",
        "\n",
        "                if len(clean_means) == 12:\n",
        "                    mmm_value = max(clean_means)\n",
        "                    clim_results[code] = {\n",
        "                        \"mmm\": mmm_value,\n",
        "                        \"monthly_means\": clean_means\n",
        "                    }\n",
        "                    print(f\"   ‚úÖ {code} MMM: {mmm_value:.4f}\")\n",
        "                else:\n",
        "                    print(f\"   ‚ùå {code}: Data bulan tidak lengkap.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå Error processing {code}: {e}\")\n",
        "\n",
        "        ds.close()\n",
        "        return clim_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"CRITICAL ERROR CLIMATOLOGY: {e}\")\n",
        "        return {}\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MODUL HARIAN (PANDAS & NUMPY) -- FIXED BAA LOGIC --\n",
        "# ==============================================================================\n",
        "class RegionAnalyzer:\n",
        "    def __init__(self, name, code, climatology_data):\n",
        "        self.name = name\n",
        "        self.code = code\n",
        "        self.stress_window = deque(maxlen=84) # 12 minggu untuk DHW\n",
        "        self.baa_window = deque(maxlen=7)     # 7 hari untuk BAA Composite\n",
        "        self.center_lat = 0.0\n",
        "        self.center_lon = 0.0\n",
        "        self.coord_set = False\n",
        "\n",
        "        # Data Climatology dari Tahap 1\n",
        "        self.mmm = climatology_data.get('mmm', 0.0)\n",
        "        self.monthly_means = climatology_data.get('monthly_means', [0.0]*12)\n",
        "\n",
        "    def process_day(self, date_obj, file_hs, file_sst=None, file_ssta=None):\n",
        "        try:\n",
        "            # 1. Baca HS\n",
        "            df_hs = pd.read_csv(file_hs, sep='\\s+', header=None, names=['lon', 'lat', 'val'])\n",
        "            df_hs = df_hs.dropna()\n",
        "            if df_hs.empty: return None\n",
        "\n",
        "            # Ambil koordinat pusat (Rata-rata seluruh piksel dalam mask)\n",
        "            if not self.coord_set:\n",
        "                self.center_lon = df_hs['lon'].mean()\n",
        "                self.center_lat = df_hs['lat'].mean()\n",
        "                self.coord_set = True\n",
        "\n",
        "            # 2. Hitung 90th Percentile HS\n",
        "            hs_values = df_hs['val'].values\n",
        "            hs_90 = np.percentile(hs_values, 90)\n",
        "\n",
        "            # Cari indeks piksel untuk mengambil SST di lokasi yang sama\n",
        "            idx_p90 = (np.abs(hs_values - hs_90)).argmin()\n",
        "\n",
        "            # 3. Ambil SST & SSTA (Jika ada)\n",
        "            sst_val = -999.0\n",
        "            sst_min = -999.0\n",
        "            sst_max = -999.0\n",
        "            ssta_val = -999.0\n",
        "\n",
        "            if file_sst and os.path.exists(file_sst):\n",
        "                try:\n",
        "                    df_sst = pd.read_csv(file_sst, sep='\\s+', header=None, names=['lon', 'lat', 'val'])\n",
        "                    sst_val = df_sst['val'].iloc[idx_p90]\n",
        "                    sst_min = df_sst['val'].min()\n",
        "                    sst_max = df_sst['val'].max()\n",
        "                except: pass\n",
        "\n",
        "            if file_ssta and os.path.exists(file_ssta):\n",
        "                try:\n",
        "                    df_ssta = pd.read_csv(file_ssta, sep='\\s+', header=None, names=['lon', 'lat', 'val'])\n",
        "                    ssta_val = df_ssta['val'].iloc[idx_p90]\n",
        "                except: pass\n",
        "\n",
        "            # 4. Hitung DHW (Akumulasi)\n",
        "            daily_stress = 0.0\n",
        "            if hs_90 >= 1.0:\n",
        "                daily_stress = hs_90 / 7.0\n",
        "\n",
        "            self.stress_window.append(daily_stress)\n",
        "            current_dhw = sum(self.stress_window)\n",
        "\n",
        "            # 5. Hitung BAA (Logika Baru: Instantaneous -> 7-Day Max)\n",
        "            # Tentukan level alert instan hari ini\n",
        "            # 0: No Stress, 1: Watch, 2: Warning, 3: Alert Lvl 1, 4: Alert Lvl 2\n",
        "            daily_alert_level = 0\n",
        "\n",
        "            if hs_90 <= 0.0:\n",
        "                daily_alert_level = 0 # No Stress\n",
        "            elif 0.0 < hs_90 < 1.0:\n",
        "                daily_alert_level = 1 # Watch\n",
        "            else: # hs_90 >= 1.0\n",
        "                if current_dhw < 4.0:\n",
        "                    daily_alert_level = 2 # Warning (Possible Bleaching)\n",
        "                elif 4.0 <= current_dhw < 8.0:\n",
        "                    daily_alert_level = 3 # Alert Level 1\n",
        "                elif current_dhw >= 8.0:\n",
        "                    daily_alert_level = 4 # Alert Level 2\n",
        "\n",
        "            # Masukkan ke window 7 hari\n",
        "            self.baa_window.append(daily_alert_level)\n",
        "\n",
        "            # Ambil nilai maksimum dalam 7 hari terakhir (Composite)\n",
        "            final_baa = max(self.baa_window) if self.baa_window else 0\n",
        "\n",
        "            return {\n",
        "                \"date\": date_obj,\n",
        "                \"sst_min\": sst_min,\n",
        "                \"sst_max\": sst_max,\n",
        "                \"sst_90\": sst_val,\n",
        "                \"ssta_90\": ssta_val,\n",
        "                \"hs_90\": max(0, hs_90),\n",
        "                \"dhw\": current_dhw,\n",
        "                \"baa\": final_baa # Menggunakan hasil composite\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading daily file {file_hs}: {e}\")\n",
        "            return None\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. MAIN EXECUTION\n",
        "# ==============================================================================\n",
        "def main():\n",
        "    if not os.path.exists(OUTPUT_FOLDER): os.makedirs(OUTPUT_FOLDER)\n",
        "\n",
        "    # --- TAHAP 1: HITUNG CLIMATOLOGY ---\n",
        "    clim_data_store = calculate_climatology_data()\n",
        "\n",
        "    if not clim_data_store:\n",
        "        print(\"‚ö†Ô∏è  Peringatan: Data Climatology Kosong/Gagal. Melanjutkan dengan nilai default 0.\")\n",
        "\n",
        "    # --- TAHAP 2: INVENTARISASI FILE HARIAN ---\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"   MEMULAI ANALISIS HARIAN (Folder: {INPUT_FOLDER_XYZ})\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if not os.path.exists(INPUT_FOLDER_XYZ):\n",
        "        print(f\"‚ùå Folder Input XYZ tidak ditemukan: {INPUT_FOLDER_XYZ}\")\n",
        "        return\n",
        "\n",
        "    files_map = {}\n",
        "\n",
        "    # Scanning folder\n",
        "    for f in os.listdir(INPUT_FOLDER_XYZ):\n",
        "        if not f.endswith(\".xyz\"): continue\n",
        "\n",
        "        name_lower = f.lower()\n",
        "        if \"np_\" in name_lower: region = \"NP\"\n",
        "        elif \"gm_\" in name_lower: region = \"GM\"\n",
        "        elif \"gn_\" in name_lower: region = \"GN\"\n",
        "        else: continue\n",
        "\n",
        "        date_match = re.search(r\"(\\d{8})\", f)\n",
        "        if not date_match: continue\n",
        "        date_str = date_match.group(1)\n",
        "\n",
        "        ftype = \"UNKNOWN\"\n",
        "        if \"hs\" in name_lower and \"hotspot\" not in name_lower: ftype = \"HS\"\n",
        "        elif \"hotspot\" in name_lower: ftype = \"HS\"\n",
        "        elif \"ssta\" in name_lower: ftype = \"SSTA\"\n",
        "        elif \"sst\" in name_lower: ftype = \"SST\"\n",
        "\n",
        "        if region not in files_map: files_map[region] = {}\n",
        "        if date_str not in files_map[region]: files_map[region][date_str] = {}\n",
        "\n",
        "        files_map[region][date_str][ftype] = os.path.join(INPUT_FOLDER_XYZ, f)\n",
        "\n",
        "    # --- TAHAP 3: PROSES DAN TULIS LAPORAN ---\n",
        "    full_names = {\"NP\": \"Nusa Penida\", \"GM\": \"Gili Matra\", \"GN\": \"Gita Nada\"}\n",
        "\n",
        "    for code, dates_dict in files_map.items():\n",
        "        region_fullname = full_names.get(code, code)\n",
        "        print(f\"\\nüìà Memproses Wilayah: {region_fullname} ({code})\")\n",
        "\n",
        "        # Ambil data climatology spesifik untuk region ini\n",
        "        site_clim = clim_data_store.get(code, {'mmm': 0.0, 'monthly_means': [0.0]*12})\n",
        "\n",
        "        analyzer = RegionAnalyzer(region_fullname, code, site_clim)\n",
        "        sorted_dates = sorted(dates_dict.keys())\n",
        "        results_buffer = []\n",
        "\n",
        "        # Loop Harian\n",
        "        for d_str in sorted_dates:\n",
        "            files = dates_dict[d_str]\n",
        "            if \"HS\" not in files: continue\n",
        "\n",
        "            dt_obj = datetime.datetime.strptime(d_str, \"%Y%m%d\")\n",
        "            data = analyzer.process_day(\n",
        "                dt_obj,\n",
        "                files[\"HS\"],\n",
        "                files.get(\"SST\"),\n",
        "                files.get(\"SSTA\")\n",
        "            )\n",
        "            if data: results_buffer.append(data)\n",
        "\n",
        "        if not results_buffer: continue\n",
        "\n",
        "        # Menulis File Output\n",
        "        output_filename = os.path.join(OUTPUT_FOLDER, f\"{region_fullname.replace(' ','_')}_NOAA_Combined.txt\")\n",
        "\n",
        "        with open(output_filename, \"w\") as f:\n",
        "            # HEADER\n",
        "            f.write(\"Name:\\n\")\n",
        "            f.write(f\"{region_fullname}\\n\\n\")\n",
        "            f.write(\"Polygon Middle Longitude:\\n\")\n",
        "            f.write(f\"{analyzer.center_lon:.4f} \\n\\n\")\n",
        "            f.write(\"Polygon Middle Latitude:\\n\")\n",
        "            f.write(f\"{analyzer.center_lat:.4f} \\n\\n\")\n",
        "\n",
        "            # --- DATA CLIMATOLOGY ---\n",
        "            f.write(\"Averaged Maximum Monthly Mean:\\n\")\n",
        "            f.write(f\"{analyzer.mmm:.4f}\\n\\n\")\n",
        "\n",
        "            f.write(\"Averaged Monthly Mean (Jan-Dec):\\n\")\n",
        "            means_str = \" \".join([f\"{val:.4f}\" for val in analyzer.monthly_means])\n",
        "            f.write(f\"{means_str}\\n\\n\")\n",
        "\n",
        "            # --- TANGGAL VALID ---\n",
        "            first_dt = results_buffer[0]['date']\n",
        "            dhw_valid_dt = first_dt + datetime.timedelta(weeks=12)\n",
        "            baa_valid_dt = dhw_valid_dt + datetime.timedelta(days=7)\n",
        "\n",
        "            f.write(\"First Valid DHW Date:\\n\")\n",
        "            f.write(f\"{dhw_valid_dt.strftime('%Y %m %d')}\\n\\n\")\n",
        "            f.write(\"First Valid BAA Date:\\n\")\n",
        "            f.write(f\"{baa_valid_dt.strftime('%Y %m %d')}\\n\\n\")\n",
        "\n",
        "            # TABEL DATA\n",
        "            header = \"YYYY MM DD SST_MIN SST_MAX SST@90th_HS SSTA@90th_HS 90th_HS>0 DHW_from_90th_HS>1 BAA_7day_max\"\n",
        "            f.write(header + \"\\n\")\n",
        "\n",
        "            for row in results_buffer:\n",
        "                d = row['date']\n",
        "                line = (\n",
        "                    f\"{d.year:4d} {d.month:02d} {d.day:02d} \"\n",
        "                    f\"{row['sst_min']:7.4f} {row['sst_max']:7.4f} \"\n",
        "                    f\"{row['sst_90']:11.4f} {row['ssta_90']:12.4f} \"\n",
        "                    f\"{row['hs_90']:9.4f} \"\n",
        "                    f\"{row['dhw']:18.4f} \"\n",
        "                    f\"{row['baa']:12d}\"\n",
        "                )\n",
        "                f.write(line + \"\\n\")\n",
        "\n",
        "        print(f\"‚úÖ Laporan tersimpan: {output_filename}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"PROSES SELESAI SEMUA\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTN90X-eu0LN",
        "outputId": "5a9d40e1-544d-4bc2-8b66-00a76241ea32"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "==================================================\n",
            "   MEMULAI PERHITUNGAN CLIMATOLOGY (NetCDF)\n",
            "==================================================\n",
            "‚úÇÔ∏è  Memotong area Lombok...\n",
            "üîÑ Processing Climatology: GM\n",
            "   ‚úÖ GM MMM: 29.0514\n",
            "üîÑ Processing Climatology: GN\n",
            "   ‚úÖ GN MMM: 28.6450\n",
            "üîÑ Processing Climatology: NP\n",
            "   ‚úÖ NP MMM: 28.4726\n",
            "\n",
            "==================================================\n",
            "   MEMULAI ANALISIS HARIAN (Folder: /content/drive/MyDrive/MAGANG/CORAL/03_Masking_Site)\n",
            "==================================================\n",
            "\n",
            "üìà Memproses Wilayah: Gili Matra (GM)\n",
            "‚úÖ Laporan tersimpan: /content/drive/MyDrive/MAGANG/CORAL/NOAA_Final_Reports_Integrated/Gili_Matra_NOAA_Combined.txt\n",
            "\n",
            "üìà Memproses Wilayah: Gita Nada (GN)\n",
            "‚úÖ Laporan tersimpan: /content/drive/MyDrive/MAGANG/CORAL/NOAA_Final_Reports_Integrated/Gita_Nada_NOAA_Combined.txt\n",
            "\n",
            "üìà Memproses Wilayah: Nusa Penida (NP)\n",
            "‚úÖ Laporan tersimpan: /content/drive/MyDrive/MAGANG/CORAL/NOAA_Final_Reports_Integrated/Nusa_Penida_NOAA_Combined.txt\n",
            "\n",
            "==================================================\n",
            "PROSES SELESAI SEMUA\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Tentukan folder mana yang mau di-zip (SUMBER)\n",
        "folder_to_zip = \"/content/drive/MyDrive/MAGANG/CORAL/NOAA_Final_Reports\"\n",
        "\n",
        "# 2. Tentukan nama file zip-nya (TUJUAN)\n",
        "# Jangan gunakan nama yang sama persis dengan folder aslinya agar tidak bingung\n",
        "# File akan disimpan di folder CORAL dengan nama \"02_Clip_lombok_DOWNLOAD.zip\"\n",
        "zip_destination = \"/content/drive/MyDrive/MAGANG/CORAL/NOAA_Final_Reports\"\n",
        "\n",
        "# 3. Eksekusi\n",
        "print(f\"üì¶ Sedang men-zip folder: {folder_to_zip} ...\")\n",
        "\n",
        "# make_archive(nama_file_tujuan, format, folder_sumber)\n",
        "shutil.make_archive(zip_destination, 'zip', folder_to_zip)\n",
        "\n",
        "print(f\"‚úÖ Selesai! File tersimpan: {zip_destination}.zip\")\n",
        "\n",
        "# 4. Download\n",
        "print(\"‚¨áÔ∏è Mendownload ke Laptop...\")\n",
        "files.download(f\"{zip_destination}.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "JPgNgBJXnpW-",
        "outputId": "fe205d71-ad76-44a4-9c21-61a4c183f95f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Sedang men-zip folder: /content/drive/MyDrive/MAGANG/CORAL/NOAA_Final_Reports ...\n",
            "‚úÖ Selesai! File tersimpan: /content/drive/MyDrive/MAGANG/CORAL/NOAA_Final_Reports.zip\n",
            "‚¨áÔ∏è Mendownload ke Laptop...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8bc16a71-8486-4476-95d2-8bed8eb37c48\", \"NOAA_Final_Reports.zip\", 1297)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}